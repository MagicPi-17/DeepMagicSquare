{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Optimizer.Optimizer import Optimizer\n",
    "from LossFunctions.GapLoss import GapLoss\n",
    "from LossFunctions.SumLoss import SumLoss\n",
    "from LossFunctions.EqualityLoss import EqualityLoss\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5000: Parameters =\n",
      "[15.0, 20.0, 5.0, 9.0, 17.0] 66.0\n",
      "[11.0, 19.0, 24.0, 6.0, 7.0] 67.0\n",
      "[14.0, 11.0, 3.0, 23.0, 15.0] 66.0\n",
      "[4.0, 13.0, 12.0, 21.0, 16.0] 66.0\n",
      "[25.0, 2.0, 22.0, 8.0, 10.0] 67.0\n",
      "\n",
      "[69.0, 65.0, 66.0, 67.0, 65.0]\n",
      "Sum of diagonals: [68.0, 64.0]\n",
      "\n",
      "Iteration 5000, GapLoss Raw Loss = 0.09750869870185852 1.9999999992598405\n",
      "Iteration 5000, SumLoss Raw Loss = 0.01768694818019867 2.0\n",
      "Iteration 5000, EqualityLoss Raw Loss = 17.46805191040039 1.999728518642235\n",
      "Iteration 5000: Scaled Total Loss = 404.42388916015625\n",
      "====================\n",
      "Iteration 10000: Parameters =\n",
      "[15.0, 16.0, 4.0, 8.0, 20.0] 63.0\n",
      "[7.0, 23.0, 21.0, 6.0, 10.0] 67.0\n",
      "[14.0, 11.0, 3.0, 22.0, 17.0] 67.0\n",
      "[5.0, 12.0, 13.0, 18.0, 17.0] 65.0\n",
      "[25.0, 2.0, 24.0, 9.0, 5.0] 65.0\n",
      "\n",
      "[66.0, 64.0, 65.0, 63.0, 69.0]\n",
      "Sum of diagonals: [64.0, 66.0]\n",
      "\n",
      "Iteration 10000, GapLoss Raw Loss = 0.0070365727879107 2.0\n",
      "Iteration 10000, SumLoss Raw Loss = 0.0005325981182977557 2.0\n",
      "Iteration 10000, EqualityLoss Raw Loss = 15.970638275146484 2.0\n",
      "Iteration 10000: Scaled Total Loss = 3554.69677734375\n",
      "====================\n",
      "Iteration 15000: Parameters =\n",
      "[13.0, 19.0, 2.0, 12.0, 22.0] 68.0\n",
      "[11.0, 23.0, 21.0, 9.0, 3.0] 67.0\n",
      "[15.0, 12.0, 5.0, 17.0, 16.0] 65.0\n",
      "[6.0, 8.0, 14.0, 18.0, 19.0] 65.0\n",
      "[20.0, 2.0, 24.0, 10.0, 7.0] 63.0\n",
      "\n",
      "[65.0, 64.0, 66.0, 66.0, 67.0]\n",
      "Sum of diagonals: [66.0, 64.0]\n",
      "\n",
      "Iteration 15000, GapLoss Raw Loss = 0.03772008791565895 2.0\n",
      "Iteration 15000, SumLoss Raw Loss = 2.716665403568186e-05 2.0\n",
      "Iteration 15000, EqualityLoss Raw Loss = 14.057456970214844 2.0\n",
      "Iteration 15000: Scaled Total Loss = 20190.447265625\n",
      "====================\n",
      "Iteration 20000: Parameters =\n",
      "[13.0, 18.0, 2.0, 9.0, 23.0] 65.0\n",
      "[10.0, 24.0, 20.0, 8.0, 4.0] 66.0\n",
      "[16.0, 11.0, 7.0, 17.0, 14.0] 65.0\n",
      "[5.0, 5.0, 15.0, 18.0, 20.0] 63.0\n",
      "[21.0, 7.0, 22.0, 12.0, 3.0] 65.0\n",
      "\n",
      "[65.0, 65.0, 66.0, 64.0, 64.0]\n",
      "Sum of diagonals: [65.0, 64.0]\n",
      "\n",
      "Iteration 20000, GapLoss Raw Loss = 0.09015799313783646 1.9999999999998361\n",
      "Iteration 20000, SumLoss Raw Loss = 0.0037845175247639418 2.0\n",
      "Iteration 20000, EqualityLoss Raw Loss = 6.75787353515625 1.9999981999131535\n",
      "Iteration 20000: Scaled Total Loss = 256.61883544921875\n",
      "====================\n",
      "Iteration 25000: Parameters =\n",
      "[14.0, 18.0, 1.0, 9.0, 23.0] 65.0\n",
      "[12.0, 22.0, 19.0, 10.0, 2.0] 65.0\n",
      "[15.0, 11.0, 6.0, 18.0, 16.0] 66.0\n",
      "[4.0, 6.0, 13.0, 19.0, 21.0] 63.0\n",
      "[20.0, 7.0, 25.0, 8.0, 3.0] 63.0\n",
      "\n",
      "[65.0, 64.0, 64.0, 64.0, 65.0]\n",
      "Sum of diagonals: [64.0, 65.0]\n",
      "\n",
      "Iteration 25000, GapLoss Raw Loss = 0.2090088129043579 1.999999944916803\n",
      "Iteration 25000, SumLoss Raw Loss = 0.0013188421726226807 2.0\n",
      "Iteration 25000, EqualityLoss Raw Loss = 8.694942474365234 2.0\n",
      "Iteration 25000: Scaled Total Loss = 4232.63330078125\n",
      "====================\n",
      "Iteration 30000: Parameters =\n",
      "[15.0, 17.0, 3.0, 6.0, 23.0] 64.0\n",
      "[11.0, 22.0, 19.0, 10.0, 4.0] 66.0\n",
      "[14.0, 12.0, 5.0, 18.0, 16.0] 65.0\n",
      "[4.0, 8.0, 13.0, 21.0, 20.0] 66.0\n",
      "[20.0, 7.0, 24.0, 9.0, 2.0] 62.0\n",
      "\n",
      "[64.0, 66.0, 64.0, 64.0, 65.0]\n",
      "Sum of diagonals: [65.0, 66.0]\n",
      "\n",
      "Iteration 30000, GapLoss Raw Loss = 0.033487241715192795 2.0\n",
      "Iteration 30000, SumLoss Raw Loss = 0.00025298967375420034 2.0\n",
      "Iteration 30000, EqualityLoss Raw Loss = 10.916828155517578 2.0\n",
      "Iteration 30000: Scaled Total Loss = 2610.973876953125\n",
      "====================\n",
      "Iteration 35000: Parameters =\n",
      "[14.0, 17.0, 4.0, 6.0, 24.0] 65.0\n",
      "[13.0, 22.0, 19.0, 9.0, 4.0] 67.0\n",
      "[15.0, 11.0, 5.0, 18.0, 16.0] 65.0\n",
      "[3.0, 7.0, 12.0, 22.0, 21.0] 65.0\n",
      "[20.0, 8.0, 25.0, 10.0, 2.0] 65.0\n",
      "\n",
      "[65.0, 65.0, 65.0, 65.0, 67.0]\n",
      "Sum of diagonals: [65.0, 65.0]\n",
      "\n",
      "Iteration 35000, GapLoss Raw Loss = 0.03120610862970352 2.0\n",
      "Iteration 35000, SumLoss Raw Loss = 5.603433965006843e-05 2.0\n",
      "Iteration 35000, EqualityLoss Raw Loss = 4.249092102050781 1.99999998063517\n",
      "Iteration 35000: Scaled Total Loss = 206.35023498535156\n",
      "====================\n",
      "Iteration 40000: Parameters =\n",
      "[12.0, 16.0, 6.0, 8.0, 24.0] 66.0\n",
      "[11.0, 23.0, 19.0, 9.0, 3.0] 65.0\n",
      "[20.0, 10.0, 4.0, 14.0, 18.0] 66.0\n",
      "[2.0, 9.0, 15.0, 22.0, 17.0] 65.0\n",
      "[20.0, 7.0, 22.0, 13.0, 4.0] 66.0\n",
      "\n",
      "[65.0, 65.0, 66.0, 66.0, 66.0]\n",
      "Sum of diagonals: [65.0, 66.0]\n",
      "\n",
      "Iteration 40000, GapLoss Raw Loss = 0.06561747193336487 2.0\n",
      "Iteration 40000, SumLoss Raw Loss = 0.0003542813064996153 2.0\n",
      "Iteration 40000, EqualityLoss Raw Loss = 6.3233184814453125 1.2013715419100583\n",
      "Iteration 40000: Scaled Total Loss = 28.421619415283203\n",
      "====================\n",
      "Iteration 45000: Parameters =\n",
      "[13.0, 15.0, 6.0, 8.0, 24.0] 66.0\n",
      "[10.0, 23.0, 18.0, 8.0, 5.0] 64.0\n",
      "[20.0, 11.0, 4.0, 12.0, 17.0] 64.0\n",
      "[2.0, 9.0, 16.0, 22.0, 17.0] 66.0\n",
      "[19.0, 7.0, 21.0, 14.0, 3.0] 64.0\n",
      "\n",
      "[64.0, 65.0, 65.0, 64.0, 66.0]\n",
      "Sum of diagonals: [65.0, 64.0]\n",
      "\n",
      "Iteration 45000, GapLoss Raw Loss = 0.008683033287525177 2.0\n",
      "Iteration 45000, SumLoss Raw Loss = 0.004090596921741962 2.0\n",
      "Iteration 45000, EqualityLoss Raw Loss = 8.51547622680664 1.9966075256573306\n",
      "Iteration 45000: Scaled Total Loss = 115.49310302734375\n",
      "====================\n",
      "Iteration 50000: Parameters =\n",
      "[15.0, 14.0, 4.0, 8.0, 22.0] 63.0\n",
      "[6.0, 25.0, 18.0, 13.0, 5.0] 67.0\n",
      "[23.0, 9.0, 2.0, 11.0, 19.0] 64.0\n",
      "[3.0, 9.0, 16.0, 21.0, 17.0] 66.0\n",
      "[20.0, 7.0, 24.0, 10.0, 5.0] 66.0\n",
      "\n",
      "[67.0, 64.0, 64.0, 63.0, 68.0]\n",
      "Sum of diagonals: [68.0, 66.0]\n",
      "\n",
      "Iteration 50000, GapLoss Raw Loss = 0.024591216817498207 2.0\n",
      "Iteration 50000, SumLoss Raw Loss = 7.149698649300262e-05 2.0\n",
      "Iteration 50000, EqualityLoss Raw Loss = 19.80510711669922 1.2226053634233112\n",
      "Iteration 50000: Scaled Total Loss = 41.271018981933594\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([14.7871, 13.7633,  3.7884,  8.0576, 21.9838,  6.1174, 24.6942, 18.0844,\n",
       "        12.5209,  5.2612, 22.9919,  8.7727,  1.8673, 11.4507, 19.0969,  2.7758,\n",
       "         9.3993, 15.8238, 20.9361, 16.8849, 19.9270,  7.1171, 23.8762, 10.3576,\n",
       "         4.5119], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "n_square = n ** 2\n",
    "params = [torch.tensor(np.random.uniform(low=7.5, high=9.5), requires_grad=True) for _ in range(n_square)]\n",
    "\n",
    "optimizer = Optimizer(params)\n",
    "\n",
    "gap_error = GapLoss(importance=10, n=n_square)\n",
    "optimizer.add_loss_function(gap_error)\n",
    "\n",
    "sum_error = SumLoss(importance=2, n=n_square)\n",
    "optimizer.add_loss_function(sum_error)\n",
    "\n",
    "equality_error = EqualityLoss(importance=5, targetValue=65, n=n)\n",
    "optimizer.add_loss_function(equality_error)\n",
    "\n",
    "optimizer.minimize(learning_rate=0.1, num_iterations=50000, display_every=5000, display_log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
